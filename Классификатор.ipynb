{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификатор акустических событий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.signal import hamming\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для построения признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_signal(filename):\n",
    "    '''Считать аудифайл'''\n",
    "    \n",
    "    _, data = wavfile.read(filename)\n",
    "    \n",
    "    return (data - data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_chunk(data, threshold, k):\n",
    "    ''' \n",
    "    Проверить, что доля абсолютных отсчётов больших порога превышает k.\n",
    "    Т.е. доля отсчётов, которые возможно принадлежат событию.\n",
    "    '''\n",
    "    \n",
    "    count = reduce(lambda acum, x : acum + (x > threshold), np.abs(data)) + 1\n",
    "    \n",
    "    return count > len(data) * k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_chunk(data, threshold, k, n, window):\n",
    "    ''' Умножение на окно и получение спектра для отрезка'''\n",
    "    \n",
    "    if check_chunk(data, threshold, k):\n",
    "        data *= window(n)\n",
    "        \n",
    "        return (True, np.abs(fft(data, n))[1 : int(n/2)])\n",
    "    else:   \n",
    "        return (False, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(data, threshold, k, n, window, m):\n",
    "    '''\n",
    "    Получение среднего спектра сигнала по отрезкам где предположительно нет шума\n",
    "    \n",
    "    data - сигнал\n",
    "    threshold - порог для отсечения шумового отрезка\n",
    "    k - минимальная доля нешумовых отсчётов в отрезке \n",
    "    n - количество точек для Фурье\n",
    "    window - применяемое окно\n",
    "    m - минимальная доля отрезков, на которых был посчитан спектр\n",
    "    '''\n",
    "    \n",
    "    result = []\n",
    "    i = 0\n",
    "    count = 0\n",
    "    \n",
    "    while i < data.size and i + n < data.size:\n",
    "        tmp = get_transform_chunk(data[i:i + n], threshold, k, n, window)\n",
    "        i += n\n",
    "        \n",
    "        # Если отрезок не шумовой добавли в список спектр данного отрезка\n",
    "        if tmp[0]:\n",
    "            count += 1\n",
    "            result.append(tmp[1])\n",
    "    \n",
    "    # Если доля отрезков, на которых был посчитан спектр больше m,\n",
    "    # то вернуть среднее всех отрезков(средний спектр по всем отрезкам)\n",
    "    \n",
    "    # Иначе пройти по всему сигналу и посчитать спектр на каждом отрезке\n",
    "    \n",
    "    if count > (data.size / n) * m:\n",
    "        return sum(map(lambda x : x / count, result))\n",
    "    else:\n",
    "        result = []\n",
    "        i = 0\n",
    "        count = 0\n",
    "        \n",
    "        while i < data.size and i + n < data.size:\n",
    "            tmp = get_transform_chunk(data[i:i + n], threshold, 0, n, window)\n",
    "            i += n\n",
    "        \n",
    "        if tmp[0]:\n",
    "            count += 1\n",
    "            result.append(tmp[1])\n",
    "            \n",
    "        return sum(map(lambda x : x / count, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Извлечение меток классов обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('./meta/meta.txt', sep='\\t', header=None, index_col=0)\n",
    "\n",
    "meta.drop([1, 2, 3], axis=1, inplace=True)\n",
    "\n",
    "meta.index.name = 'name'\n",
    "meta.columns = ['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_class = {'background' : 1, 'bags' : 2, 'door' : 3, 'keyboard' : 4, 'knocking_door' : 5, 'ring' : 6, 'speech' : 7, 'tool' : 8}\n",
    "\n",
    "class_to_name = {value : key for key, value in name_to_class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.zeros(11307)\n",
    "\n",
    "for index, file in enumerate(os.listdir('./audio')):\n",
    "    y_train[index] = name_to_class[meta['class'][file]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение признаков обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((11307, 511))\n",
    "\n",
    "for index, file in enumerate(os.listdir('./audio')):\n",
    "    data = read_signal('./audio' + '/' + file) \n",
    "    X_train[index] = get_transform(data, np.median(np.abs(data)), 0.2, 1024, hamming, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96905393, 0.96905393, 0.96816976])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=141)\n",
    "\n",
    "model_to_set = RandomForestClassifier(criterion='entropy', max_depth=50, n_estimators=500, random_state=141, n_jobs=-1)\n",
    "\n",
    "cross_val_score(model_to_set, X_train, y_train, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=141, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = model_to_set\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на тест сете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = open('result.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('./test'):\n",
    "    \n",
    "    data = read_signal('./test' + '/' + file) \n",
    "    data = get_transform(data, np.median(np.abs(data)), 0.2, 1024, hamming, 0.1)\n",
    "    \n",
    "    predicted_probs = clf.predict_proba(data.reshape((1, 511)))[0]\n",
    "    max_predicted_proba = max(predicted_probs)\n",
    "    predicted_class = class_to_name[int(clf.predict(data.reshape((1, 511)))[0])]\n",
    "  \n",
    "    result.write(file + '\\t' + str(max_predicted_proba) + '\\t' + predicted_class + '\\n')\n",
    "    \n",
    "#     if file.find('unknown') == -1:\n",
    "#     # Для открытой задачи\n",
    "#         result.write(file + '\\t' + str(max_predicted_proba) + '\\t' + predicted_class + '\\n')\n",
    "#     elif max_predicted_proba > 0.65:\n",
    "#     # Если классификатор достаточно уверен\n",
    "#         result.write(file + '\\t' + str(max_predicted_proba) + '\\t' + predicted_class + '\\n')\n",
    "#     elif max_predicted_proba > 0.4 and sorted(np.abs(predicted_probs - max_predicted_proba))[1] >= 0.35:\n",
    "#     # Если классификатор уверен не очень сильно, но остальные вероятности намного меньше\n",
    "#         result.write(file + '\\t' + str(max_predicted_proba) + '\\t' + predicted_class + '\\n')\n",
    "#     else:\n",
    "#     # Классификатор слабо уверен или есть несколько равных не очень больших вероятностей\n",
    "#         result.write(file + '\\t' + str(predicted_probs) + '\\t' + 'unknown' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
